#!/usr/bin/env bash

#1) If site-update already running, kill it through lock file (kill -15 wait, check kill -9 wait)
#2) Get lock
#3) Backup ghost directory to S3 backup bucket
#4) generate static site
#5) Sync static site to S3 www bucket
#6) Invalidate CloudFront

source $(dirname $0)/../.env

# Backup content images
aws s3 sync --delete --no-follow-symlinks --no-progress $GHOST_DIR/content/images $CMS_BUCKET_PREFIX/images

echo "*** pulling down website"
gssg --domain https://${CMS_HOSTNAME} --url https://${WEB_HOSTNAME}  --dest $WEB_DIR

if [ "$GHOST_API_KEY" != "" ]
then
  mkdir -p $WEB_DIR/files
  echo "download posts for ghostHunter"
  curl "https://${CMS_HOSTNAME}/ghost/api/v2/content/posts/?key=${GHOST_API_KEY}&limit=all&include=tags" |
    perl -ne "s/${CMS_HOSTNAME}/${WEB_HOSTNAME}" > $WEB_DIR/files/posts.json
  last=$(jq -r '.posts | sort_by(.published_at) | reverse | limit(1;.[]) | .published_at' $WEB_DIR/files/posts.json)
  echo '{"latestPost": "'$last'"}' > $WEB_DIR/files/posts.latest.json
fi

echo "*** syncing to web site bucket"
aws s3 sync --delete --no-progress $WEB_DIR $WEB_BUCKET_PREFIX
echo "*** invalidating cloudfront"

# Upload public files
for DIR in $(find $GHOST_DIR/content -name public_files)
do
  aws s3 sync --no-progress $DIR $WEB_BUCKET_CMS_BUCKET_PREFIX/files
done

aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_ID --paths '/*'
echo "*** all done publishing"